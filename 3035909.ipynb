{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "这次比赛参考了https://aistudio.baidu.com/aistudio/projectdetail/1206845 的方案，在划分训练集和验证集上进行了修改尝试，尝试划分训练集：验证集=90:10；95:5；80：20。 95：5的结果徘徊于86.78左右，80:20结果徘徊于85.8左右，可以推测划分在9:1左右的时候可以达到最大值，也可以周围小幅度再次细化。同时对学习率进行了调整，在原模型0.0007的基础上进行略微下调与上调，情况不太可观。同时对epoch进行增加，发现随着epoch的增加，结果会随之下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 飞桨常规赛：反欺诈预测11月第7名方案\n",
    "- 1.数据预处理：\n",
    "- 2.数据读取部分（Reader类）。\n",
    "- 3.网络部分\n",
    "- 4.模型训练、预测\n",
    "- 5.总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.数据预处理部分:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from paddle.io import Dataset\n",
    "from baseline_tools import Data2IdNorm,Data2IdEmb,value2numpy,make_dict_file\n",
    "TAGS = {'android_id': None,\n",
    "        'apptype': \"emb\",\n",
    "        'carrier': \"emb\",\n",
    "        'dev_height': \"emb\",\n",
    "        'dev_ppi': \"emb\",\n",
    "        'dev_width': \"emb\",\n",
    "        'lan': \"emb\",\n",
    "        'media_id': \"emb\",\n",
    "        'ntt': \"emb\",\n",
    "        'os': \"emb\",\n",
    "        'osv': \"emb\",\n",
    "        'package': \"emb\",\n",
    "        'sid': None,\n",
    "        'timestamp': \"norm\",\n",
    "        'version': \"emb\",\n",
    "        'fea_hash': \"norm\",\n",
    "        'location': \"emb\",\n",
    "        'fea1_hash': \"norm\",\n",
    "        'cus_type': \"emb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datas = pd.read_csv(\"train.csv\")\n",
    "\n",
    "for ids,data in enumerate(datas[\"fea_hash\"]):\n",
    "    try:\n",
    "        data = float(data)\n",
    "    except:\n",
    "        datas[\"fea_hash\"][ids] = 499997879\n",
    "        print(ids+1)\n",
    "datas.to_csv(\"train.csv\")\n",
    "datas = pd.read_csv(\"test.csv\",dtype=str)\n",
    "\n",
    "\n",
    "for ids,data in enumerate(datas[\"fea_hash\"]):\n",
    "    try:\n",
    "        data = float(data)\n",
    "    except:\n",
    "        datas[\"fea_hash\"][ids] = 499997879\n",
    "        print(ids+1)\n",
    "datas = datas\n",
    "datas.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘emb_dicts’: File exists\n",
      "apptype 字典生成完毕,共 89 个id\n",
      "carrier 字典生成完毕,共 5 个id\n",
      "dev_height 字典生成完毕,共 798 个id\n",
      "dev_ppi 字典生成完毕,共 92 个id\n",
      "dev_width 字典生成完毕,共 346 个id\n",
      "lan 字典生成完毕,共 22 个id\n",
      "media_id 字典生成完毕,共 284 个id\n",
      "ntt 字典生成完毕,共 8 个id\n",
      "os 字典生成完毕,共 2 个id\n",
      "osv 字典生成完毕,共 155 个id\n",
      "package 字典生成完毕,共 1950 个id\n",
      "timestamp_max的倒数:6.409861939473897e-13 -------- 780048002158.7462\n",
      "timestamp_max:1560096004317.4924 --------min: 1559491201174.7812\n",
      "version 字典生成完毕,共 22 个id\n",
      "fea_hash_max的倒数:2.3283201561138293e-10 -------- 2147470994.0\n",
      "fea_hash_max:4294941988.0 --------min: 0.0\n",
      "location 字典生成完毕,共 332 个id\n",
      "fea1_hash_max的倒数:2.3299594677571534e-10 -------- 2145960077.5\n",
      "fea1_hash_max:4291920155.0 --------min: 12400.0\n",
      "cus_type 字典生成完毕,共 58 个id\n",
      "全部生成完毕\n"
     ]
    }
   ],
   "source": [
    "%mkdir emb_dicts\r\n",
    "TRAIN_PATH = \"train.csv\"\r\n",
    "SAVE_PATH = \"emb_dicts\"\r\n",
    "df = pd.read_csv(TRAIN_PATH, index_col=0)\r\n",
    "\r\n",
    "pack = dict()\r\n",
    "for tag, tag_method in TAGS.items():\r\n",
    "    if tag_method != \"emb\":\r\n",
    "        if tag_method == \"norm\":\r\n",
    "            data = df.loc[:, tag]\r\n",
    "            print(\"{}_max的倒数:{}\".format(tag,1/float(data.max())),\"--------\",float(data.max())/2)\r\n",
    "            print(\"{}_max:{}\".format(tag,float(data.max())),\"--------min:\",float(data.min()))\r\n",
    "        continue\r\n",
    "    data = df.loc[:, tag]\r\n",
    "    dict_size = make_dict_file(data, SAVE_PATH, dict_name=tag)\r\n",
    "    pack[tag] = dict_size + 1  \r\n",
    "\r\n",
    "with open(os.path.join(SAVE_PATH, \"size.dict\"), \"w\", encoding=\"utf-8\") as f:\r\n",
    "    f.write(str(pack))\r\n",
    "\r\n",
    "print(\"全部生成完毕\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NORM_WEIGHT = {'timestamp': 6.409845522722902e-13,\r\n",
    "                \"fea_hash\":2.3283201561138293e-10,\r\n",
    "                \"fea1_hash\":2.3299594677571534e-10,\r\n",
    "                \"android_id\":1.4086530e-06,\r\n",
    "                \"dev_height\":0.00011081560283687943,\r\n",
    "                \"dev_ppi\":0.001388888888888889,\r\n",
    "                \"dev_width\":0.00011322463768115942\r\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.数据读取部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_size_dict(dict_path=\"./emb_dicts/size.dict\"):\r\n",
    "    with open(dict_path, \"r\", encoding=\"utf-8\") as f:\r\n",
    "        try:\r\n",
    "            size_dict = eval(f.read())\r\n",
    "        except Exception as e:\r\n",
    "            print(\"size_dict打开失败，\", dict_path, \"文件是否正常，报错信息如下:\\n\", e)\r\n",
    "        return size_dict\r\n",
    "\r\n",
    "class Reader(Dataset):\r\n",
    "    def __init__(self,\r\n",
    "                 is_infer: bool = False,\r\n",
    "                 is_val: bool = False,\r\n",
    "                 use_mini_train: bool = False,\r\n",
    "                 emb_dict_path=\"./emb_dicts\"):\r\n",
    "        super().__init__()\r\n",
    "        train_name = \"mini_train\" if use_mini_train else \"train\"\r\n",
    "        file_name = \"test\" if is_infer else train_name\r\n",
    "        df = pd.read_csv(file_name + \".csv\")\r\n",
    "\r\n",
    "        DATA_RATIO = 0.9\r\n",
    "        if is_infer:\r\n",
    "            self.df = df.reset_index()\r\n",
    "        else:\r\n",
    "            start_index = 0 if not is_val else int(len(df) * DATA_RATIO)\r\n",
    "            end_index = int(len(df) * DATA_RATIO) if not is_val else int(len(df) * 1)#len(df)\r\n",
    "            self.df = df.loc[start_index:end_index].reset_index()\r\n",
    "        # 数据预处理\r\n",
    "        self.cols = [tag for tag, tag_method in TAGS.items() if tag_method is not None]\r\n",
    "        self.methods = dict()\r\n",
    "        for col in self.cols:\r\n",
    "            if TAGS[col] == \"emb\":\r\n",
    "                self.methods[col] = Data2IdEmb(dict_path=emb_dict_path, dict_name=col).get_method()\r\n",
    "            elif TAGS[col] == \"norm\":\r\n",
    "                self.methods[col] = Data2IdNorm(norm_weight=NORM_WEIGHT[col]).get_method()\r\n",
    "            else:\r\n",
    "                raise Exception(str(TAGS) + \"是未知的预处理方案\")\r\n",
    "        self.add_label = not is_infer\r\n",
    "        self.is_val = is_val\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        pack = []\r\n",
    "        for col in self.cols:\r\n",
    "            sample = self.df.loc[index, col]\r\n",
    "            sample = self.methods[col](sample)\r\n",
    "            pack.append(sample)\r\n",
    "        if self.add_label:\r\n",
    "            tag_data = self.df.loc[index, \"label\"]\r\n",
    "            tag_data = np.array(tag_data).astype(\"int64\")\r\n",
    "            pack.append(tag_data)\r\n",
    "            return pack\r\n",
    "        else:\r\n",
    "            return pack\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import paddle.tensor as tensor\r\n",
    "from paddle.static import InputSpec\r\n",
    "from paddle.metric import Accuracy\r\n",
    "class SampleNet(paddle.nn.Layer):\r\n",
    "    def __init__(self, tag_dict: dict, size_dict: dict):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "        self.hidden_layers_list = []\r\n",
    "        out_layer_input_size = 0\r\n",
    "        self.relu = paddle.nn.LeakyReLU()\r\n",
    "        self.drop = paddle.nn.Dropout(p=0.2)\r\n",
    "        self.dict_list = ['emb', 'emb', 'emb', 'emb', 'emb', 'emb', 'emb', 'emb', 'emb', 'emb', 'emb', 'norm', 'emb', 'norm', 'emb', 'norm', 'emb']\r\n",
    "\r\n",
    "        for tag, tag_method in tag_dict.items():\r\n",
    "            if tag_method == \"emb\":\r\n",
    "                emb = nn.Embedding(num_embeddings=size_dict[tag], embedding_dim=EMB_SIZE)\r\n",
    "                self.hidden_layers_list.append(emb)\r\n",
    "            elif tag_method == \"norm\":\r\n",
    "                continue\r\n",
    "            elif tag_method is None:\r\n",
    "                continue\r\n",
    "            else:\r\n",
    "                raise Exception(str(tag_method) + \"为未知的处理方案\")\r\n",
    "        \r\n",
    "        self.lstm = nn.LSTM(EMB_SIZE, 128, 1)\r\n",
    "        self.lin_emb = nn.Linear(in_features=128, out_features=EMB_LINEAR_SIZE)\r\n",
    "        self.lin_norm1 = nn.Linear(in_features=1, out_features=3)\r\n",
    "        self.lin_norm2 = nn.Linear(in_features=3, out_features=1)\r\n",
    "        self.out_layers = nn.Linear(in_features=899,\r\n",
    "                                    out_features=42)\r\n",
    "        self.out_layers1 = nn.Linear(in_features=42,\r\n",
    "                            out_features=2)\r\n",
    "\r\n",
    "  \r\n",
    "    def forward(self, *input_data):\r\n",
    "        layer_list = []  \r\n",
    "        num_id = 0\r\n",
    "        for sample_data, tag_method in zip(input_data, self.dict_list):\r\n",
    "            tmp = sample_data\r\n",
    "            if tag_method == \"emb\":\r\n",
    "                emb = self.hidden_layers_list[num_id]\r\n",
    "                tmp = emb(tmp)\r\n",
    "                tmp, (_, _) = self.lstm(tmp)\r\n",
    "                tmp = self.lin_emb(tmp)\r\n",
    "                tmp = self.relu(tmp)\r\n",
    "                num_id += 1\r\n",
    "            elif tag_method == \"norm\":\r\n",
    "                tmp = self.lin_norm1(tmp)\r\n",
    "                tmp = self.relu(tmp)\r\n",
    "                tmp = self.lin_norm2(tmp)\r\n",
    "                tmp = self.relu(tmp)\r\n",
    "            elif tag_method is None:\r\n",
    "                continue\r\n",
    "            else:\r\n",
    "                raise Exception(str(tag_method) + \"为未知的处理方案\")\r\n",
    "            layer_list.append(tensor.flatten(tmp, start_axis=1))  \r\n",
    "\r\n",
    "        layers = tensor.concat(layer_list, axis=1)\r\n",
    "        layers = self.out_layers(layers)\r\n",
    "        layers = self.relu(layers)\r\n",
    "        layers = self.drop(layers)\r\n",
    "        layers = self.out_layers1(layers)\r\n",
    "        result = self.relu(layers)\r\n",
    "        \r\n",
    "        result = paddle.nn.functional.softmax(result)\r\n",
    "\r\n",
    "        return result\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4.模型训练、预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1217 19:06:05.080075   140 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1217 19:06:05.085245   140 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "# 模型保存与加载文件夹\r\n",
    "SAVE_DIR = \"./output/\"\r\n",
    "\r\n",
    "# 推理部分\r\n",
    "IS_INFER = False  \r\n",
    "TEST_BATCH_SIZE = 32  \r\n",
    "RESULT_FILE = \"./result.csv\" \r\n",
    "\r\n",
    "# 超参数\r\n",
    "EPOCHS = 2  # 训练循环，epoch增加则结果下降\r\n",
    "TRAIN_BATCH_SIZE = 1 \r\n",
    "EMB_SIZE = 128  \r\n",
    "EMB_LINEAR_SIZE = 64  \r\n",
    "\r\n",
    "# 训练环境\r\n",
    "USE_MINI_DATA = False  \r\n",
    "USE_GPU = False  \r\n",
    "\r\n",
    "paddle.disable_static(place=paddle.CUDAPlace(0) if USE_GPU else paddle.CPUPlace())\r\n",
    "# 定义网络输入\r\n",
    "inputs = []\r\n",
    "for tag_name, tag_m in TAGS.items():\r\n",
    "    d_type = \"float32\"\r\n",
    "    if tag_m == \"emb\":\r\n",
    "        d_type = \"int64\"\r\n",
    "    if tag_m is None:\r\n",
    "        continue\r\n",
    "    inputs.append(InputSpec(shape=[-1, 1], dtype=d_type, name=tag_name))\r\n",
    "# 定义Label\r\n",
    "labels = [InputSpec([-1, 1], 'int64', name='label')]\r\n",
    "\r\n",
    "# 实例化SampleNet以及Reader\r\n",
    "model = paddle.Model(SampleNet(TAGS, get_size_dict()), inputs=inputs, labels=labels)\r\n",
    "\r\n",
    "# 推理部分\r\n",
    "if IS_INFER:\r\n",
    "    pass\r\n",
    "\r\n",
    "#直接训练完推理结果\r\n",
    "else:\r\n",
    "\r\n",
    "    train_reader = Reader(use_mini_train=USE_MINI_DATA)\r\n",
    "    val_reader = Reader(use_mini_train=USE_MINI_DATA, is_val=True)\r\n",
    "    optimizer = paddle.optimizer.Adam(learning_rate=0.0007, parameters=model.parameters())#learning_rate可修改\r\n",
    "    \r\n",
    "    model.prepare(optimizer, paddle.nn.loss.CrossEntropyLoss(), Accuracy())\r\n",
    "\r\n",
    "    model.fit(train_data=train_reader,  \r\n",
    "              eval_data=val_reader,  \r\n",
    "              batch_size=TRAIN_BATCH_SIZE,  \r\n",
    "              epochs=EPOCHS, \r\n",
    "              log_freq=1000,  \r\n",
    "              save_dir=SAVE_DIR) \r\n",
    "    \r\n",
    "\r\n",
    "    infer_reader = Reader(is_infer=True)\r\n",
    "\r\n",
    "    model.prepare()\r\n",
    "    infer_output = model.predict(infer_reader, TEST_BATCH_SIZE)\r\n",
    " \r\n",
    "    result_df = infer_reader.df.loc[:, \"sid\"]\r\n",
    "    pack = []\r\n",
    "    for batch_out in infer_output[0]:\r\n",
    "        for sample in batch_out:\r\n",
    "            pack.append(np.argmax(sample))\r\n",
    "    # 保存csv文件\r\n",
    "    result_df = pd.DataFrame({\"sid\": np.array(result_df, dtype=\"int64\"), \"label\": pack})\r\n",
    "    result_df.to_csv(RESULT_FILE, index=False)\r\n",
    "    print(\"结果文件保存至：\", RESULT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 6.总结：\n",
    "因为在将近11月底才接触这个比赛，只能在官方给出baseline的参数上进行一些细化分析。\n",
    "1.在划分训练集和验证集上进行了修改尝试，尝试划分训练集：验证集=90:10；95:5；80：20。   95：5的结果徘徊于86.78左右，80:20结果徘徊于85.8左右，可以推测划分在9:1左右的时候可以达到最大值，也可以周围小幅度再次细化。\n",
    "2.对学习率进行了调整，在原模型0.0007的基础上进行略微下调与上调，情况不太可观。\n",
    "3.对epoch进行增加，发现随着epoch的增加，结果会随之下降。\n",
    "***因为运行一次需要花费的时间有10小时左右，所以简单训练了一下，达到了87.3947分。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
